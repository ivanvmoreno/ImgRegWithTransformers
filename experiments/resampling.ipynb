{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.ndimage as nd\n",
    "import SimpleITK as sitk\n",
    "import skimage.color as color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/data/dataset_medium.csv\"\n",
    "dataset_path = \"/data/ANHIR_Data\"\n",
    "output_path = \"/data/ANHIR_Parsed_1024_Original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_max_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(case_id, dataset_path, load_masks=False):\n",
    "    base_path = os.path.join(dataset_path, str(case_id))\n",
    "    source_path = os.path.join(base_path, \"source.mha\")\n",
    "    target_path = os.path.join(base_path, \"target.mha\")\n",
    "    if load_masks:\n",
    "        source_mask_path = os.path.join(base_path, \"source_mask.mha\")\n",
    "        target_mask_path = os.path.join(base_path, \"target_mask.mha\")\n",
    "    source_landmarks_path = os.path.join(base_path, \"source_landmarks.csv\")\n",
    "    target_landmarks_path = os.path.join(base_path, \"target_landmarks.csv\")\n",
    "\n",
    "    source = sitk.GetArrayFromImage(sitk.ReadImage(source_path))\n",
    "    target = sitk.GetArrayFromImage(sitk.ReadImage(target_path))\n",
    "    if load_masks:\n",
    "        source_mask = sitk.GetArrayFromImage(sitk.ReadImage(source_mask_path))\n",
    "        target_mask = sitk.GetArrayFromImage(sitk.ReadImage(target_mask_path))\n",
    "    source_landmarks = pd.read_csv(source_landmarks_path).to_numpy()[:, 1:]\n",
    "    try:\n",
    "        status = \"training\"\n",
    "        target_landmarks = pd.read_csv(target_landmarks_path).to_numpy()[:, 1:]\n",
    "    except:\n",
    "        status = \"evaluation\"\n",
    "        target_landmarks = None\n",
    "    if load_masks:\n",
    "        return source, target, source_landmarks, target_landmarks, status, source_mask, target_mask\n",
    "    else:\n",
    "        return source, target, source_landmarks, target_landmarks, status,\n",
    "\n",
    "\n",
    "def resample_image(image, resample_factor):\n",
    "    if len(image.shape) == 3:\n",
    "        y_size, x_size, _ = image.shape\n",
    "        grid_y, grid_x, grid_z = np.mgrid[0:y_size:resample_factor, 0:x_size:resample_factor, 0:3]\n",
    "        resampled_image = nd.map_coordinates(image, [grid_y, grid_x, grid_z], cval=0, order=3)\n",
    "    else:\n",
    "        y_size, x_size = image.shape\n",
    "        grid_y, grid_x = np.mgrid[0:y_size:resample_factor, 0:x_size:resample_factor]\n",
    "        resampled_image = nd.map_coordinates(image, [grid_y, grid_x], cval=0, order=3)\n",
    "    return resampled_image\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    min_val = np.min(image, axis=(0, 1))\n",
    "    max_val = np.max(image, axis=(0, 1))\n",
    "    return np.where(max_val != min_val, (image - min_val) / (max_val - min_val), image)\n",
    "\n",
    "\n",
    "def load_landmarks(landmarks_path):\n",
    "    landmarks = pd.read_csv(landmarks_path)\n",
    "    landmarks = landmarks.to_numpy()[:, 1:]\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def pad_landmarks(landmarks, old_shape, new_shape):\n",
    "    new_landmarks = landmarks.copy()\n",
    "    new_landmarks[:, 0] += int(np.floor((new_shape[1] - old_shape[1])/2))\n",
    "    new_landmarks[:, 1] += int(np.floor((new_shape[0] - old_shape[0])/2))\n",
    "    return new_landmarks\n",
    "\n",
    "\n",
    "def pad_images_np(source, target):\n",
    "    if len(source.shape) == 3:\n",
    "        y_size_source, x_size_source, _ = source.shape\n",
    "    else:\n",
    "        y_size_source, x_size_source = source.shape\n",
    "\n",
    "    if len(target.shape) == 3:\n",
    "        y_size_target, x_size_target, _ = target.shape\n",
    "    else:\n",
    "        y_size_target, x_size_target = target.shape\n",
    "    \n",
    "    new_y_size = max(y_size_source, y_size_target)\n",
    "    new_x_size = max(x_size_source, x_size_target)\n",
    "    new_shape = (new_y_size, new_x_size)\n",
    "\n",
    "    padded_source = pad_single(source, new_shape)\n",
    "    padded_target = pad_single(target, new_shape)\n",
    "    return padded_source, padded_target\n",
    "\n",
    "\n",
    "def pad_single(image, new_shape):\n",
    "    if len(image.shape) == 3:\n",
    "        y_size, x_size, _ = image.shape\n",
    "        y_pad = ((new_shape[0] - y_size) // 2, (new_shape[0] - y_size) // 2)\n",
    "        x_pad = ((new_shape[1] - x_size) // 2, (new_shape[1] - x_size) // 2)\n",
    "        z_pad = (0, 0)\n",
    "        pad_width = (y_pad, x_pad, z_pad)\n",
    "    else:\n",
    "        y_size, x_size = image.shape\n",
    "        y_pad = ((new_shape[0] - y_size) // 2, (new_shape[0] - y_size) // 2)\n",
    "        x_pad = ((new_shape[1] - x_size) // 2, (new_shape[1] - x_size) // 2)\n",
    "        pad_width = (y_pad, x_pad)\n",
    "\n",
    "    new_image = np.pad(image, pad_width, constant_values=0)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def resample_landmarks(landmarks, resample_ratio):\n",
    "    new_landmarks = landmarks / resample_ratio\n",
    "    return new_landmarks\n",
    "\n",
    "\n",
    "def save_landmarks(landmarks, landmarks_path):\n",
    "    df = pd.DataFrame(landmarks)\n",
    "    df.to_csv(landmarks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv(csv_path)\n",
    "current_case = None ,csv_file.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                          0\n",
       "Image diagonal [pixels]                       17997.0\n",
       "Image size [pixels]                     (16308, 7612)\n",
       "Source image                COAD_01/scale-25pc/S1.jpg\n",
       "Source landmarks            COAD_01/scale-25pc/S1.csv\n",
       "Target image                COAD_01/scale-25pc/HE.jpg\n",
       "Target landmarks            COAD_01/scale-25pc/HE.csv\n",
       "status                                     evaluation\n",
       "Warped target landmarks                           NaN\n",
       "Warped source landmarks                           NaN\n",
       "Execution time [minutes]                          NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_case[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "current_id = current_case[1]['Unnamed: 0']\n",
    "size = current_case[1]['Image size [pixels]']\n",
    "diagonal = int(current_case[1]['Image diagonal [pixels]'])\n",
    "y_size, x_size = int(size.split(\",\")[0][1:]), int(size.split(\",\")[1][:-1])\n",
    "source_path = current_case[1]['Source image']\n",
    "target_path = current_case[1]['Target image']\n",
    "source_landmarks_path = current_case[1]['Source landmarks']\n",
    "target_landmarks_path = current_case[1]['Target landmarks']\n",
    "status = current_case[1]['status']\n",
    "\n",
    "source_path = os.path.join(dataset_path, source_path)\n",
    "target_path = os.path.join(dataset_path, target_path)\n",
    "source_landmarks_path = os.path.join(dataset_path, source_landmarks_path)\n",
    "target_landmarks_path = os.path.join(dataset_path, target_landmarks_path)\n",
    "\n",
    "source_landmarks = load_landmarks(source_landmarks_path)\n",
    "\n",
    "if status == \"training\":\n",
    "    target_landmarks = load_landmarks(target_landmarks_path)\n",
    "\n",
    "source = cv2.cvtColor(cv2.imread(source_path), cv2.COLOR_BGR2RGB)\n",
    "target = cv2.cvtColor(cv2.imread(target_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "source = 1 - normalize(source)\n",
    "target = 1 - normalize(target)\n",
    "\n",
    "padded_source, padded_target = pad_images_np(source, target)\n",
    "padded_source_landmarks = pad_landmarks(source_landmarks, source.shape, padded_source.shape)\n",
    "\n",
    "if status == \"training\":\n",
    "    padded_target_landmarks = pad_landmarks(target_landmarks, target.shape, padded_target.shape)\n",
    "\n",
    "resample_factor = np.max(padded_source.shape) / output_max_size\n",
    "gaussian_sigma = resample_factor / 1.25\n",
    "\n",
    "smoothed_source = nd.gaussian_filter(padded_source, gaussian_sigma)\n",
    "smoothed_target = nd.gaussian_filter(padded_target, gaussian_sigma)\n",
    "\n",
    "resampled_source = resample_image(smoothed_source, resample_factor)\n",
    "resampled_target = resample_image(smoothed_target, resample_factor)\n",
    "resampled_source_landmarks = resample_landmarks(padded_source_landmarks, resample_factor)\n",
    "\n",
    "if status == \"training\":\n",
    "    resampled_target_landmarks = resample_landmarks(padded_target_landmarks, resample_factor)\n",
    "\n",
    "# save jpeg\n",
    "if not os.path.isdir(os.path.dirname(os.path.join(output_path, str(current_id)))):\n",
    "    os.makedirs(os.path.join(os.path.join(output_path, str(current_id))))\n",
    "\n",
    "to_save_source_jpg_path = os.path.join(output_path, str(current_id), \"source.jpg\")\n",
    "to_save_target_jpg_path = os.path.join(output_path, str(current_id), \"target.jpg\")\n",
    "\n",
    "to_save_source_jpg = cv2.cvtColor((resampled_source * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "to_save_target_jpg = cv2.cvtColor((resampled_target * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# to_save_source_jpg = cv2.cvtColor(resampled_source, cv2.COLOR_RGB2BGR)\n",
    "# to_save_target_jpg = cv2.cvtColor(resampled_target, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2.imwrite(to_save_source_jpg_path, to_save_source_jpg)\n",
    "cv2.imwrite(to_save_target_jpg_path, to_save_target_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(15,10))\n",
    "axs[0].imshow(source, cmap='gray')\n",
    "axs[0].set_title(\"Fixed Image\")\n",
    "axs[1].imshow(target, cmap='gray')\n",
    "axs[1].set_title(\"Moving Image\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
